{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V3_qTKTP3Zf",
        "outputId": "3bdedcea-dd69-47d3-9a99-07e7b3cdb6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "ERROR: unknown command \"installinstall\" - maybe you meant \"install\"\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Mounted at /content/drive\n",
            "Index(['ID', 'Age', 'Gender', 'Height', 'Weight', 'CALC', 'FAVC', 'FCVC',\n",
            "       'NCP', 'SCC', 'SMOKE', 'CH2O', 'family_history_with_overweight', 'FAF',\n",
            "       'TUE', 'CAEC', 'MTRANS', 'NObeyesdad'],\n",
            "      dtype='object')\n",
            "Index(['ID', 'Age', 'Gender', 'Height', 'Weight', 'CALC', 'FAVC', 'FCVC',\n",
            "       'NCP', 'SCC', 'SMOKE', 'CH2O', 'family_history_with_overweight', 'FAF',\n",
            "       'TUE', 'CAEC', 'MTRANS'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in X_train: 5020\n",
            "Missing values in y_train: 0\n",
            "Resampled X_train shape: (2030, 24)\n",
            "Resampled y_train shape: (2030,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['CALC' 'SCC' 'family_history_with_overweight']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n",
            "Training F1-Score:  1.0\n",
            "['.config', 'drive', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install xgboost\n",
        "!pip installinstall imbalanced-learn\n",
        "!pip install scikit-learn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import pandas and numpy packet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read train csv file\n",
        "sample_data = pd.read_csv(\"/content/drive/MyDrive/ml dataset/sample_submission.csv\")\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ml dataset/train (1).csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/ml dataset/test.csv\")\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# check column names in the train and test data\n",
        "print(train_data.columns)\n",
        "print(test_data.columns)\n",
        "\n",
        "# calculate BMI (assuming 'Height and 'Weight' columns exist in both train_data and test_data set)\n",
        "train_data['BMI'] = train_data['Weight'] / ((train_data['Height'] / 100) ** 2)\n",
        "test_data['BMI'] = test_data['Weight'] / ((test_data['Height'] / 100) ** 2)\n",
        "\n",
        "# separate categorical and numerical features\n",
        "categorical_cols = ['Gender', 'FAVC', 'SMOKE', 'CAEC', 'MTRANS']  # Adjust based on your dataset\n",
        "numerical_cols = ['Age', 'Height', 'Weight', 'CALC', 'FCVC', 'NCP', 'SCC', 'CH2O', 'family_history_with_overweight', 'FAF', 'TUE', 'BMI']\n",
        "\n",
        "train_categorical = train_data[categorical_cols]\n",
        "train_numerical = train_data[numerical_cols]\n",
        "\n",
        "test_categorical = test_data[categorical_cols]\n",
        "test_numerical = test_data[numerical_cols]\n",
        "\n",
        "\n",
        "# Apply Label Encoding for categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit on the combined unique values from both train and test data\n",
        "for col in categorical_cols:\n",
        "    all_values = pd.concat([train_data[col], test_data[col]]).unique()\n",
        "    label_encoder.fit(all_values)  # Fit on all unique values\n",
        "    train_data[col] = label_encoder.transform(train_data[col])\n",
        "    test_data[col] = label_encoder.transform(test_data[col])\n",
        "\n",
        "\n",
        "\n",
        "# Handle missing values (if any) in numerical columns (filling with mean)\n",
        "# Ensure we are working only with numerical data\n",
        "train_numerical = train_numerical.apply(pd.to_numeric, errors='coerce')\n",
        "test_numerical = test_numerical.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_numerical.fillna(train_numerical.mean(), inplace=True)\n",
        "test_numerical.fillna(test_numerical.mean(), inplace=True)\n",
        "\n",
        "# Feature scaling for numerical columns\n",
        "scaler = StandardScaler()\n",
        "X_train_numerical = scaler.fit_transform(train_numerical)\n",
        "X_test_numerical = scaler.transform(test_numerical)\n",
        "\n",
        "# Combine the processed categorical and numerical data\n",
        "X_train = pd.concat([pd.DataFrame(X_train_numerical, columns=numerical_cols), train_categorical.reset_index(drop=True)], axis=1)\n",
        "X_test = pd.concat([pd.DataFrame(X_test_numerical, columns=numerical_cols), test_categorical.reset_index(drop=True)], axis=1)\n",
        "\n",
        "\n",
        "# Define target variable\n",
        "y_train = train_data['NObeyesdad']\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd  # Make sure pandas is imported\n",
        "\n",
        "# Check for missing values again\n",
        "print(\"Missing values in X_train:\", X_train.isnull().sum().sum())\n",
        "print(\"Missing values in y_train:\", y_train.isnull().sum())\n",
        "\n",
        "# Separate numerical and categorical features in X_train\n",
        "X_train_numerical = X_train.select_dtypes(include=np.number)\n",
        "X_train_categorical = X_train.select_dtypes(exclude=np.number)\n",
        "\n",
        "# Use SimpleImputer only on numerical features\n",
        "imputer = SimpleImputer(strategy='mean')  # Using mean to fill missing values\n",
        "X_train_numerical_imputed = imputer.fit_transform(X_train_numerical)\n",
        "\n",
        "# Convert the imputed numerical data back to a DataFrame\n",
        "# Instead of using X_train_numerical.columns, use the columns present after imputation.\n",
        "X_train_numerical_imputed_df = pd.DataFrame(X_train_numerical_imputed, columns=imputer.get_feature_names_out(), index=X_train_numerical.index)\n",
        "# Get the feature names as strings\n",
        "\n",
        "# Combine the imputed numerical and original categorical features\n",
        "X_train_imputed = pd.concat([X_train_numerical_imputed_df, X_train_categorical], axis=1)\n",
        "\n",
        "# Convert categorical features to numerical using one-hot encoding\n",
        "X_train_imputed = pd.get_dummies(X_train_imputed, columns=X_train_categorical.columns) #This line was added to fix the problem\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_imputed, y_train)\n",
        "\n",
        "# Check the shape of the resampled dataset\n",
        "print(\"Resampled X_train shape:\", X_train_resampled.shape)\n",
        "print(\"Resampled y_train shape:\", y_train_resampled.shape)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Encode the target variable (y_train_resampled) to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_resampled_encoded = label_encoder.fit_transform(y_train_resampled)\n",
        "\n",
        "# XGBoost Model and Hyperparameter Tuning\n",
        "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "grid_search.fit(X_train_resampled, y_train_resampled_encoded)  # Use encoded labels\n",
        "\n",
        "# Best Model\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the resampled training set\n",
        "y_pred_train = best_xgb_model.predict(X_train_resampled)\n",
        "\n",
        "# Inverse transform predictions to original labels for evaluation\n",
        "y_pred_train_original = label_encoder.inverse_transform(y_pred_train)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(\"Training Accuracy: \", accuracy_score(y_train_resampled, y_pred_train_original))\n",
        "print(\"Training F1-Score: \", f1_score(y_train_resampled, y_pred_train_original, average='weighted'))\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Combine test and train datasets if required for consistent encoding\n",
        "all_data = pd.concat([X_train, X_test], axis=0)\n",
        "\n",
        "# Apply one-hot encoding to object columns\n",
        "object_columns = all_data.select_dtypes(include=['object']).columns\n",
        "all_data_encoded = pd.get_dummies(all_data, columns=object_columns)\n",
        "\n",
        "# Split back into train and test\n",
        "X_train_encoded = all_data_encoded.iloc[:len(X_train), :]\n",
        "X_test_encoded = all_data_encoded.iloc[len(X_train):, :]\n",
        "\n",
        "import os\n",
        "print(os.listdir())  # Check if 'final_submission.csv' is listed\n",
        "\n",
        "# Import necessary libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert object columns to 'category' dtype for XGBoost\n",
        "categorical_columns = ['Gender', 'FAVC', 'SMOKE', 'CAEC', 'MTRANS']  # List of categorical columns\n",
        "for col in categorical_columns:\n",
        "    X_train[col] = X_train[col].astype('category')\n",
        "    X_test[col] = X_test[col].astype('category')\n",
        "\n",
        "# Encode the target variable 'y_train' from string to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Train the model with enable_categorical\n",
        "best_xgb_model = xgb.XGBClassifier(tree_method='hist', enable_categorical=True)\n",
        "best_xgb_model.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict using the model\n",
        "test_predictions = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Convert numeric predictions back to the original string labels\n",
        "test_predictions_str = label_encoder.inverse_transform(test_predictions)\n",
        "\n",
        "# Create the submission DataFrame using the predicted values\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_data['ID'],  # Using 'ID' from the test dataset\n",
        "    'NObeyesdad': test_predictions_str  # Using predicted string labels\n",
        "})\n",
        "\n",
        "# Save the submission file in the correct path\n",
        "submission.to_csv('/content/drive/MyDrive/ml dataset/submit.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nmgfVyjVP7G6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}